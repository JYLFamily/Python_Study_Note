{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type:  <class 'numpy.ndarray'>\ndata shape:  (20, 2)\ntarget type:  <class 'numpy.ndarray'>\ntarget shape:  (20,)\ntarget set:  {0, 1, 2}\n[[ 0.89562636 -0.95309531]\n [ 1.04321307  1.43628205]\n [ 1.2936214   1.67226796]\n [ 1.5602674   0.70681664]\n [-0.90607969 -1.25622872]\n [-0.86684103 -0.8998977 ]]\n[2 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "'''make_blobs 产生聚类数据集\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "\n",
    "cluster_std = 0.3\n",
    "\n",
    "data, target = make_blobs(n_samples=200\n",
    "                          , centers=centers  # 通过一个 list 指定了聚类中心位置、可以直接指定聚类中心数目\n",
    "                          , n_features=2\n",
    "                          , cluster_std=0.3\n",
    "                          , random_state=0)\n",
    "\n",
    "print(\"data type: \", type(data))\n",
    "print(\"data shape: \", data.shape)\n",
    "print(\"target type: \", type(target))\n",
    "print(\"target shape: \", target.shape)\n",
    "print(\"target set: \", set(target))  # set() 可以用去重\n",
    "print(data[0:6, :])\n",
    "print(target[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''make_classification 产生分类数据集\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "data, target = make_classification(n_samples=200\n",
    "                                   , n_features=2\n",
    "                                   , n_informative=2\n",
    "                                   , n_redundant=0\n",
    "                                   , random_state=1\n",
    "                                   , n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(0)\n",
    "data += rng.uniform(low=-2\n",
    "                    , high=2\n",
    "                    , size=data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index:  [2 3 4 5] test_index:  [0 1]\ntrain_index:  [0 1 4 5] test_index:  [2 3]\ntrain_index:  [0 1 2 3] test_index:  [4 5]\n"
     ]
    }
   ],
   "source": [
    "import  numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "data = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
    "target = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    print(\"train_index: \", train_index, \"test_index: \", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index:  [1 2 4 5] test_index:  [0 3]\ntrain_index:  [0 2 3 5] test_index:  [1 4]\ntrain_index:  [0 1 3 4] test_index:  [2 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "data = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
    "target = np.array([1, 1, 1, 2, 2, 2])\n",
    "# groups = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "sfk = StratifiedKFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in sfk.split(data, target):\n",
    "    print(\"train_index: \", train_index, \"test_index: \", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   1\n0  1   2\n1  3   4\n2  7   8\n3  9  10\n   0\n0  1\n1  2\n2  4\n3  5\n    0   1\n0   5   6\n1  11  12\n   0\n0  3\n1  6\n------------------------------------------------\n    0   1\n0   1   2\n1   5   6\n2   7   8\n3  11  12\n   0\n0  1\n1  3\n2  4\n3  6\n   0   1\n0  3   4\n1  9  10\n   0\n0  2\n1  5\n------------------------------------------------\n    0   1\n0   3   4\n1   5   6\n2   9  10\n3  11  12\n   0\n0  2\n1  3\n2  5\n3  6\n   0  1\n0  1  2\n1  7  8\n   0\n0  1\n1  4\n------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "data = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
    "target = np.array([1, 2, 3, 4, 5, 6])\n",
    "groups = np.array([0, 1, 2, 4, 5, 6])\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=3)\n",
    "group_kfold\n",
    "\n",
    "for train_index, test_index in group_kfold.split(data, target, groups):\n",
    "    print(pd.DataFrame(data[train_index, :]))\n",
    "    print(pd.DataFrame(target[train_index]))\n",
    "    print(pd.DataFrame(data[test_index, :]))\n",
    "    print(pd.DataFrame(target[test_index]))\n",
    "    print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index:  [1 2 3 4 5] test_index:  [0]\ntrain_index:  [0 2 3 4 5] test_index:  [1]\ntrain_index:  [0 1 3 4 5] test_index:  [2]\ntrain_index:  [0 1 2 4 5] test_index:  [3]\ntrain_index:  [0 1 2 3 5] test_index:  [4]\ntrain_index:  [0 1 2 3 4] test_index:  [5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "data = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
    "target = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(data)\n",
    "\n",
    "for train_index, test_index in loo.split(data):\n",
    "    print(\"train_index: \", train_index, \"test_index: \", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index:  [2 4 5 3] test_index:  [1 0]\ntrain_index:  [2 4 0 3] test_index:  [1 5]\ntrain_index:  [5 3 0 4] test_index:  [1 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "data = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
    "target = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "ss = ShuffleSplit(n_splits=3\n",
    "                  , test_size=1/3\n",
    "                  , train_size=2/3)\n",
    "\n",
    "ss.get_n_splits()\n",
    "\n",
    "for train_index, test_index in ss.split(data):\n",
    "    print(\"train_index: \", train_index, \"test_index: \", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81481481481481477"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from scipy.stats import randint as hp_randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    results = pd.DataFrame(clf.cv_results_).sort_values(by = ['rank_test_score']).head(n_top)\n",
    "    results = results.loc[:, ['rank_test_score', 'std_test_score', 'mean_test_score', 'params']].reset_index()\n",
    "    print(results.T)\n",
    "\n",
    "\n",
    "\n",
    "data, target = load_digits(return_X_y=True)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "pararmeters = {\n",
    "    'criterion':[\"gini\", \"entropy\"],\n",
    "    'max_features':hp_randint(1, 10), # 1~10 均匀分布 \n",
    "    'max_depth':hp_randint(1, 4)  # 1~4 均匀分布 \n",
    "}\n",
    "\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, \n",
    "                                                                    target, \n",
    "                                                                    test_size=0.33, \n",
    "                                                                    random_state=42)\n",
    "\n",
    "clf = RandomizedSearchCV(rf,\n",
    "                         pararmeters,\n",
    "                         n_iter=10,\n",
    "                         n_jobs=4)\n",
    "\n",
    "# Call predict on the estimator with the best found parameters.\n",
    "clf.fit(data_train, target_train)\n",
    "clf.predict(data_test)\n",
    "\n",
    "accuracy_score(target_test, clf.predict(data_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
