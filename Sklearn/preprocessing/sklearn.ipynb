{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n0           0.500000          0.343137           0.137255          0.019608\n1           0.515789          0.315789           0.147368          0.021053\n2           0.500000          0.340426           0.138298          0.021277\n3           0.489362          0.329787           0.159574          0.021277\n4           0.490196          0.352941           0.137255          0.019608\n------------------------------------\n   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n0           0.500000          0.343137           0.137255          0.019608\n1           0.515789          0.315789           0.147368          0.021053\n2           0.500000          0.340426           0.138298          0.021277\n3           0.489362          0.329787           0.159574          0.021277\n4           0.490196          0.352941           0.137255          0.019608\n------------------------------------\n   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n0           0.500000          0.343137           0.137255          0.019608\n1           0.515789          0.315789           0.147368          0.021053\n2           0.500000          0.340426           0.138298          0.021277\n3           0.489362          0.329787           0.159574          0.021277\n4           0.490196          0.352941           0.137255          0.019608\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# ------ toy ------\n",
    "def normalize_l1(sample):\n",
    "    \"\"\"\n",
    "    :param sample: DataFrame 的一行(axis=1) , 一个 Series\n",
    "    :return: 经过 l1 正则的样本 , 一个 Series\n",
    "    \"\"\"\n",
    "    return sample/sum(abs(sample))\n",
    "\n",
    "print(data.head().apply(normalize_l1, axis=1))  # 对每一个样本操作\n",
    "print('------------------------------------')\n",
    "\n",
    "# ------ normalize function ------\n",
    "print(pd.DataFrame(normalize(data, norm='l1'), columns=iris.feature_names).head())\n",
    "print('------------------------------------')\n",
    "\n",
    "# ------ Normalizer ------\n",
    "scaler = Normalizer(norm='l1').fit(data)\n",
    "print(pd.DataFrame(scaler.transform(data), columns=iris.feature_names).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n0                0.0               0.0                0.0               0.0\n1                0.0               0.0                0.0               0.0\n2                0.0               0.0                0.0               0.0\n3                0.0               0.0                0.0               0.0\n4                0.0               0.0                0.0               0.0\n------------------------------------\n   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n0                0.0               0.0                0.0               0.0\n1                0.0               0.0                0.0               0.0\n2                0.0               0.0                0.0               0.0\n3                0.0               0.0                0.0               0.0\n4                0.0               0.0                0.0               0.0\n   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n0                0.0               0.0                0.0               0.0\n1                0.0               0.0                0.0               0.0\n2                0.0               0.0                0.0               0.0\n3                0.0               0.0                0.0               0.0\n4                0.0               0.0                0.0               0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# ------ toy ------\n",
    "def binarize_one(sample):\n",
    "    \"\"\"\n",
    "    :param sample:  DataFrame 的一行(axis=1) , 一个 Series\n",
    "    :return: Series > 1 元素变为 1、Series <= 1 元素变为 0 , 一个 Series\n",
    "    \"\"\"\n",
    "    # Feature values below or equal to this are replaced by 0, above it by 1.\n",
    "    sample.loc[sample > 1] = 1\n",
    "    sample.loc[sample <= 1] = 0\n",
    "    return sample\n",
    "\n",
    "print(data.head().apply(binarize_one, axis=1))\n",
    "print('------------------------------------')\n",
    "\n",
    "# ------ binarize function ------\n",
    "print(pd.DataFrame(binarize(data, threshold=1), columns=iris.feature_names).head())\n",
    "\n",
    "# ------ Binarizer ------\n",
    "scaler = Binarizer(threshold=1).fit(data)\n",
    "print(pd.DataFrame(scaler.transform(data), columns=iris.feature_names).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8\n0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0\n1  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0\n2  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0\n3  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# The input to this transformer should be a matrix of integers, denoting the values taken on by categorical (discrete) features\n",
    "data = pd.DataFrame([['male', 'from Europe', 'uses IE'], \n",
    "              ['female', 'from US', 'uses Firefox'], \n",
    "              ['male', 'from Asia', 'uses Chrome'],\n",
    "              ['female', 'from Europe', 'uses Safari']],\n",
    "             columns=['sex', 'homeland', 'browser'])\n",
    "\n",
    "def category_to_integer(feature):\n",
    "    \"\"\"\n",
    "    :param feature: DataFrame 的一列(axis=0) , 一个 Series\n",
    "    :return: 使用 integer 编码后的 feature , 一个 Series\n",
    "    \"\"\"\n",
    "    category_to_integer = {}\n",
    "   \n",
    "    for integer, category in enumerate(np.unique(feature)):\n",
    "        category_to_integer[category] = integer\n",
    "    \n",
    "    return feature.replace(category_to_integer)\n",
    "\n",
    "data = data.apply(category_to_integer, axis=0)\n",
    "    \n",
    "# ------ OneHotEncoder ------\n",
    "enc = OneHotEncoder().fit(data)\n",
    "# scaler.transform() 返回 scipy.sparse.csr.csr_matrix 对象\n",
    "print(pd.DataFrame(enc.transform(data).toarray()).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Imputation of missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n [ 4.  3.]\n [ 7.  6.]]\n------------------------------------\n[[ 4.          3.66666667]\n [ 4.          3.66666667]\n [ 4.          3.66666667]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "data = csr_matrix([[1, 2], [0, 3], [7, 6]])\n",
    "\n",
    "imp = Imputer(missing_values=0, strategy='mean', axis=0).fit(data)\n",
    "print(imp.transform(data))\n",
    "print('------------------------------------')\n",
    "# below 可见 .transform() 不是根据传入的数据集进行特征均值填充 , 而是根据 .fit() 传入数据集得到\n",
    "print(imp.transform(csr_matrix([[0, 0], [0, 0], [0, 0]])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 15)\n------------------------------------\n(150, 11)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# ------ Polynomialfeatures ------\n",
    "poly = PolynomialFeatures(degree=2).fit(data)\n",
    "print(poly.transform(data).shape)\n",
    "print('------------------------------------')\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True).fit(data)\n",
    "print(poly.transform(data).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.62924054  1.25276297  0.33647224 -1.60943791]\n [ 1.58923521  1.09861229  0.33647224 -1.60943791]\n [ 1.54756251  1.16315081  0.26236426 -1.60943791]\n [ 1.5260563   1.13140211  0.40546511 -1.60943791]\n [ 1.60943791  1.28093385  0.33647224 -1.60943791]\n [ 1.68639895  1.36097655  0.53062825 -0.91629073]\n [ 1.5260563   1.22377543  0.33647224 -1.2039728 ]\n [ 1.60943791  1.22377543  0.40546511 -1.60943791]\n [ 1.48160454  1.06471074  0.33647224 -1.60943791]\n [ 1.58923521  1.13140211  0.40546511 -2.30258509]]\n------------------------------------\nHelloWorld\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# ------ FunctionTransformer-1 ------\n",
    "# 等价 np.log(data.values)\n",
    "# FunctionTransformer 类的存在就是封装传入的 func 函数使得有 fit()、transform()、fit_transform() 方法 \n",
    "scaler = FunctionTransformer(func=np.log).fit(data)\n",
    "print(scaler.transform(data)[0:10])\n",
    "print('------------------------------------')\n",
    "\n",
    "# ------ FunctionTransformer-2 ------\n",
    "def hello_world(X):\n",
    "    return 'HelloWorld'\n",
    "\n",
    "# func(data.values) hello_world(data.values)\n",
    "scaler = FunctionTransformer(func=hello_world).fit(data)\n",
    "print(scaler.transform(data)[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And So On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
